{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7beb99-5868-4f71-ad69-533b538aeb62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengmiao/anaconda3/envs/comp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], 'src'))\n",
    "\n",
    "processed_dir = '/data/pengmiao/PaCKD_0/processed'\n",
    "\n",
    "train_loader = torch.load(os.path.join(processed_dir, f\"bc-3.train.pt\"))\n",
    "test_loader = torch.load(os.path.join(processed_dir, f\"bc-3.test.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2f0539-4036-42b3-a2fb-64907f1fe7a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(ep, train_loader, model_save_path):\n",
    "    global steps\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#d,t: (torch.Size([64, 1, 784]),64)        \n",
    "        optimizer.zero_grad()\n",
    "        output = sigmoid(model(data))\n",
    "        loss = F.binary_cross_entropy(output, target, reduction='mean')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss/=len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = sigmoid(model(data))\n",
    "            test_loss += F.binary_cross_entropy(output, target, reduction='mean').item()\n",
    "            thresh=0.5\n",
    "            output_bin=(output>=thresh)*1\n",
    "            correct+=(output_bin&target.int()).sum()\n",
    "        test_loss /=  len(test_loader)\n",
    "        return test_loss\n",
    "\n",
    "import csv\n",
    "\n",
    "def run_epoch(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7ac37-e94a-49b6-ba4d-93d6da11539c",
   "metadata": {},
   "source": [
    "Baseline Teacher R Training No Cluster No KD, lr = 0.0001, gamma = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4200fd17-2ad1-4b90-b8cb-471bd69a5042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 0.2249865555 - test_loss: 0.2179443322\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2175688889 - test_loss: 0.2289805716\n",
      "Early Stop Left: 14\n",
      "Epoch: 3 - loss: 0.2174327775 - test_loss: 0.2206873246\n",
      "Early Stop Left: 13\n",
      "Epoch: 4 - loss: 0.2168335402 - test_loss: 0.2319437766\n",
      "Early Stop Left: 12\n",
      "Epoch: 5 - loss: 0.2145503027 - test_loss: 0.2275580301\n",
      "Early Stop Left: 11\n",
      "Epoch: 6 - loss: 0.2144655880 - test_loss: 0.2461138607\n",
      "Early Stop Left: 10\n",
      "Epoch: 7 - loss: 0.2136679025 - test_loss: 0.2222226236\n",
      "Early Stop Left: 9\n",
      "Epoch: 8 - loss: 0.2151345382 - test_loss: 0.2168030499\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 9 - loss: 0.2149396160 - test_loss: 0.2211324256\n",
      "Early Stop Left: 14\n",
      "Epoch: 10 - loss: 0.2154008062 - test_loss: 0.1998694631\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 11 - loss: 0.2167794622 - test_loss: 0.2171379208\n",
      "Early Stop Left: 14\n",
      "Epoch: 12 - loss: 0.2174248653 - test_loss: 0.2116057643\n",
      "Early Stop Left: 13\n",
      "Epoch: 13 - loss: 0.2163505160 - test_loss: 0.2081615295\n",
      "Early Stop Left: 12\n",
      "Epoch: 14 - loss: 0.2151678522 - test_loss: 0.2168187681\n",
      "Early Stop Left: 11\n",
      "Epoch: 15 - loss: 0.2146296232 - test_loss: 0.2168419860\n",
      "Early Stop Left: 10\n",
      "Epoch: 16 - loss: 0.2156595757 - test_loss: 0.2125148127\n",
      "Early Stop Left: 9\n",
      "Epoch: 17 - loss: 0.2148568422 - test_loss: 0.2191247725\n",
      "Early Stop Left: 8\n",
      "Epoch: 18 - loss: 0.2136636392 - test_loss: 0.2134002929\n",
      "Early Stop Left: 7\n",
      "Epoch: 19 - loss: 0.2150996906 - test_loss: 0.2263699538\n",
      "Early Stop Left: 6\n",
      "Epoch: 20 - loss: 0.2153421798 - test_loss: 0.2045718746\n",
      "Early Stop Left: 5\n",
      "Epoch: 21 - loss: 0.2147845266 - test_loss: 0.2151718986\n",
      "Early Stop Left: 4\n",
      "Epoch: 22 - loss: 0.2155325282 - test_loss: 0.2118728902\n",
      "Early Stop Left: 3\n",
      "Epoch: 23 - loss: 0.2157242798 - test_loss: 0.2050543761\n",
      "Early Stop Left: 2\n",
      "Epoch: 24 - loss: 0.2153952721 - test_loss: 0.2158493612\n",
      "Early Stop Left: 1\n",
      "Epoch: 25 - loss: 0.2169934228 - test_loss: 0.2065314895\n",
      "Early Stop Left: 0\n",
      "-------- Early Stop! --------\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.05)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = False\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.gamma.5.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.gamma.5.r.tsv'\n",
    "\n",
    "init_dataloader('5')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12331ea1-fd90-4258-aa0f-f828cdd9eb9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy import nanargmax, sqrt\n",
    "from sklearn.metrics import auc, f1_score, precision_score, recall_score, precision_recall_curve, roc_curve\n",
    "import numpy as np\n",
    "def threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\",topk=2,threshold=0.5):\n",
    "    y_score=np.stack(test_df[\"y_score\"])\n",
    "    y_real=np.stack(test_df[\"future\"])\n",
    "    best_threshold=0\n",
    "    if throttle_type==\"roc\":\n",
    "        print(\"throttleing by roc curve\")\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        gmeans=dict()\n",
    "        ix=dict()\n",
    "        #pdb.set_trace()\n",
    "        for i in range(BITMAP_SIZE):\n",
    "            fpr[i], tpr[i], threshold[i] =roc_curve(y_real[:,i],y_score[:,i])\n",
    "            roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "            #best:\n",
    "            gmeans[i] = sqrt(tpr[i]*(1-fpr[i]))\n",
    "            ix[i]=nanargmax(gmeans[i])\n",
    "            best_threshold_list.append(threshold[i][ix[i]])\n",
    "            #print('Dimension: i=%d, Best threshold=%f, G-Mean=%.3f' %(i, threshold[i][ix[i]], gmeans[i][ix[i]]))\n",
    "        if optimal_type==\"indiv\":\n",
    "            best_threshold=best_threshold_list\n",
    "            y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "        elif optimal_type==\"micro\":\n",
    "            fpr[\"micro\"], tpr[\"micro\"], threshold[\"micro\"] = roc_curve(y_real.ravel(), y_score.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "            #best:\n",
    "            gmeans[\"micro\"] = sqrt(tpr[\"micro\"]*(1-fpr[\"micro\"]))\n",
    "            ix[\"micro\"]=nanargmax(gmeans[\"micro\"])\n",
    "            best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "            print('Best micro threshold=%f, G-Mean=%.3f' %(best_threshold, gmeans[\"micro\"][ix[\"micro\"]]))\n",
    "            \n",
    "            y_pred_bin = (y_score-best_threshold >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "            \n",
    "    if throttle_type==\"f1\":\n",
    "        print(\"throttleing by precision-recall curve\")\n",
    "        p = dict()\n",
    "        r = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        fscore=dict()\n",
    "        ix=dict()\n",
    "        \n",
    "        p[\"micro\"], r[\"micro\"], threshold[\"micro\"]=precision_recall_curve(y_real.ravel(),y_score.ravel())\n",
    "        fscore[\"micro\"] = (2 * p[\"micro\"] * r[\"micro\"]) / (p[\"micro\"] + r[\"micro\"])\n",
    "        ix[\"micro\"]=nanargmax(fscore[\"micro\"])\n",
    "        best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "        print('Best micro threshold=%f, fscore=%.3f' %(best_threshold, fscore[\"micro\"][ix[\"micro\"]]))\n",
    "        y_pred_bin = (y_score-best_threshold >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type==\"topk\":\n",
    "        print(\"throttleing by topk:\",topk)\n",
    "        pred_index = torch.tensor(y_score).topk(topk)[1].cpu().detach().numpy()\n",
    "        y_pred_bin=[to_bitmap(a,BITMAP_SIZE) for a in pred_index]\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type ==\"fixed_threshold\":\n",
    "        print(\"throttleing by fixed threshold:\",threshold)\n",
    "        best_threshold=threshold\n",
    "        y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "    \n",
    "    return test_df, best_threshold\n",
    "\n",
    "def model_prediction(test_loader, test_df, model_save_path):\n",
    "    print(\"predicting\")\n",
    "    prediction = []\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data, _ in tqdm(test_loader):\n",
    "        output = sigmoid(model(data))\n",
    "        prediction.extend(output.cpu().detach().numpy())\n",
    "    test_df[\"y_score\"] = prediction\n",
    "\n",
    "    return test_df[['id', 'cycle', 'addr', 'ip', 'block_address', 'future', 'y_score']]\n",
    "\n",
    "def evaluate(y_test,y_pred_bin):\n",
    "    f1_score_res=f1_score(y_test, y_pred_bin, average='micro')\n",
    "    #recall: tp / (tp + fn)\n",
    "    recall_score_res=recall_score(y_test, y_pred_bin, average='micro')\n",
    "    #precision: tp / (tp + fp)\n",
    "    precision_score_res=precision_score(y_test, y_pred_bin, average='micro',zero_division=0)\n",
    "    print(\"p,r,f1:\",precision_score_res,recall_score_res,f1_score_res)\n",
    "    return precision_score_res,recall_score_res,f1_score_res\n",
    "\n",
    "def run_val(test_loader, test_df, app_name, model_save_path):\n",
    "    res = {}\n",
    "\n",
    "    print(\"Validation start\")\n",
    "    test_df = model_prediction(test_loader, test_df, model_save_path)\n",
    "    df_res, threshold=threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\")\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"app\"], res[\"opt_th\"], res[\"p\"], res[\"r\"], res[\"f1\"]=[app_name],[threshold],[p],[r],[f1]\n",
    "\n",
    "    df_res, _ =threshold_throttleing(test_df,throttle_type=\"fixed_threshold\",threshold=0.5)\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"p_5\"],  res[\"r_5\"], res[\"f1_5\"]=[p],[r],[f1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abda7b0c-39f8-45d9-b26a-cfcfe15ae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = torch.load(os.path.join(processed_dir, 'bc-3.df.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346240b1-74dd-4bea-b39d-5e40d16d0b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232/1232 [00:16<00:00, 74.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throttleing by precision-recall curve\n",
      "Best micro threshold=0.172694, fscore=0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_760903/2052061821.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.15109066106576013 0.6904550293198635 0.2479278499265169\n",
      "throttleing by fixed threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_760903/2052061821.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.8107001094735587 0.021543385897532564 0.04197143120421303\n"
     ]
    }
   ],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac91ed3d-527e-432e-9a7d-86c5193077d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 0.2302720435 - test_loss: 0.2320394492\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2178523771 - test_loss: 0.2297895878\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 3 - loss: 0.2163823675 - test_loss: 0.2294684086\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 4 - loss: 0.2163723651 - test_loss: 0.2484645673\n",
      "Early Stop Left: 14\n",
      "Epoch: 5 - loss: 0.2165643955 - test_loss: 0.2276227242\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 6 - loss: 0.2171162103 - test_loss: 0.2221536248\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 7 - loss: 0.2167922092 - test_loss: 0.2344347408\n",
      "Early Stop Left: 14\n",
      "Epoch: 8 - loss: 0.2165621888 - test_loss: 0.2183304573\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 9 - loss: 0.2163453429 - test_loss: 0.2171222698\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 10 - loss: 0.2163750105 - test_loss: 0.2148041282\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 11 - loss: 0.2166638527 - test_loss: 0.2138872603\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 12 - loss: 0.2174821046 - test_loss: 0.2137497876\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 13 - loss: 0.2175658561 - test_loss: 0.2115759810\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 14 - loss: 0.2185726910 - test_loss: 0.2170340981\n",
      "Early Stop Left: 14\n",
      "Epoch: 15 - loss: 0.2171068056 - test_loss: 0.2174646557\n",
      "Early Stop Left: 13\n",
      "Epoch: 16 - loss: 0.2171240629 - test_loss: 0.2150871333\n",
      "Early Stop Left: 12\n",
      "Epoch: 17 - loss: 0.2164593900 - test_loss: 0.2142487783\n",
      "Early Stop Left: 11\n",
      "Epoch: 18 - loss: 0.2150601575 - test_loss: 0.2112754217\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 19 - loss: 0.2139645590 - test_loss: 0.2100370480\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 20 - loss: 0.2135151090 - test_loss: 0.2081427164\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 21 - loss: 0.2134106979 - test_loss: 0.2085742070\n",
      "Early Stop Left: 14\n",
      "Epoch: 22 - loss: 0.2126153790 - test_loss: 0.2089636508\n",
      "Early Stop Left: 13\n",
      "Epoch: 23 - loss: 0.2118648399 - test_loss: 0.2071322602\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 24 - loss: 0.2105619446 - test_loss: 0.2070910771\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 25 - loss: 0.2097233512 - test_loss: 0.2045358852\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 26 - loss: 0.2100406245 - test_loss: 0.2049856283\n",
      "Early Stop Left: 14\n",
      "Epoch: 27 - loss: 0.2084032227 - test_loss: 0.2048574900\n",
      "Early Stop Left: 13\n",
      "Epoch: 28 - loss: 0.2076923281 - test_loss: 0.2064507337\n",
      "Early Stop Left: 12\n",
      "Epoch: 29 - loss: 0.2067910123 - test_loss: 0.2050137996\n",
      "Early Stop Left: 11\n",
      "Epoch: 30 - loss: 0.2065187777 - test_loss: 0.2020047091\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 31 - loss: 0.2058467973 - test_loss: 0.2026191407\n",
      "Early Stop Left: 14\n",
      "Epoch: 32 - loss: 0.2053906088 - test_loss: 0.2036448631\n",
      "Early Stop Left: 13\n",
      "Epoch: 33 - loss: 0.2050907898 - test_loss: 0.2009357049\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 34 - loss: 0.2048836745 - test_loss: 0.2052778111\n",
      "Early Stop Left: 14\n",
      "Epoch: 35 - loss: 0.2045376741 - test_loss: 0.2067183078\n",
      "Early Stop Left: 13\n",
      "Epoch: 36 - loss: 0.2046339680 - test_loss: 0.2095200694\n",
      "Early Stop Left: 12\n",
      "Epoch: 37 - loss: 0.2044077062 - test_loss: 0.2037785840\n",
      "Early Stop Left: 11\n",
      "Epoch: 38 - loss: 0.2040974413 - test_loss: 0.2065835639\n",
      "Early Stop Left: 10\n",
      "Epoch: 39 - loss: 0.2041070479 - test_loss: 0.2099187004\n",
      "Early Stop Left: 9\n",
      "Epoch: 40 - loss: 0.2039601314 - test_loss: 0.2035288436\n",
      "Early Stop Left: 8\n",
      "Epoch: 41 - loss: 0.2038278651 - test_loss: 0.2065947749\n",
      "Early Stop Left: 7\n",
      "Epoch: 42 - loss: 0.2038781177 - test_loss: 0.2120466595\n",
      "Early Stop Left: 6\n",
      "Epoch: 43 - loss: 0.2035591154 - test_loss: 0.2033859076\n",
      "Early Stop Left: 5\n",
      "Epoch: 44 - loss: 0.2034956995 - test_loss: 0.2072786888\n",
      "Early Stop Left: 4\n",
      "Epoch: 45 - loss: 0.2034344010 - test_loss: 0.2082916142\n",
      "Early Stop Left: 3\n",
      "Epoch: 46 - loss: 0.2036029651 - test_loss: 0.2093609736\n",
      "Early Stop Left: 2\n",
      "Epoch: 47 - loss: 0.2034158214 - test_loss: 0.2071754983\n",
      "Early Stop Left: 1\n",
      "Epoch: 48 - loss: 0.2032489494 - test_loss: 0.2054969972\n",
      "Early Stop Left: 0\n",
      "-------- Early Stop! --------\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = False\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.05.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.05.r.tsv'\n",
    "\n",
    "init_dataloader('2')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca678d7-00d7-4305-adc3-646fa6582a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232/1232 [00:14<00:00, 82.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throttleing by precision-recall curve\n",
      "Best micro threshold=0.143467, fscore=0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_760903/2052061821.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.1530393097630983 0.7744075420453235 0.25557215592217\n",
      "throttleing by fixed threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_760903/2052061821.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.5334083992199675 0.03881252920260777 0.07235991570148408\n"
     ]
    }
   ],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf00b98-17eb-4d5a-b9ae-9cc8b1544745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  9 22:10:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 49%   66C    P2    96W / 140W |   3956MiB / 16117MiB |     88%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4000    On   | 00000000:44:00.0 Off |                  Off |\n",
      "| 41%   29C    P8    14W / 140W |   3788MiB / 16117MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A5000    On   | 00000000:83:00.0 Off |                  Off |\n",
      "| 30%   32C    P2    93W / 230W |   6301MiB / 24256MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A5000    On   | 00000000:84:00.0 Off |                  Off |\n",
      "| 30%   20C    P8    17W / 230W |   5461MiB / 24256MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A5000    On   | 00000000:C3:00.0 Off |                  Off |\n",
      "| 30%   21C    P8    19W / 230W |   6627MiB / 24256MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A5000    On   | 00000000:C4:00.0 Off |                  Off |\n",
      "| 30%   19C    P8    17W / 230W |   5421MiB / 24256MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    757905      C   ...nda3/envs/comp/bin/python     2424MiB |\n",
      "|    0   N/A  N/A    758130      C   ...nda3/envs/comp/bin/python     1529MiB |\n",
      "|    1   N/A  N/A    760903      C   ...nda3/envs/comp/bin/python     3785MiB |\n",
      "|    2   N/A  N/A    757905      C   ...nda3/envs/comp/bin/python     2767MiB |\n",
      "|    2   N/A  N/A    758130      C   ...nda3/envs/comp/bin/python     1545MiB |\n",
      "|    2   N/A  N/A    761277      C   python                           1986MiB |\n",
      "|    3   N/A  N/A    758130      C   ...nda3/envs/comp/bin/python     3877MiB |\n",
      "|    3   N/A  N/A    758818      C   ...nda3/envs/comp/bin/python     1581MiB |\n",
      "|    4   N/A  N/A    758818      C   ...nda3/envs/comp/bin/python     3879MiB |\n",
      "|    4   N/A  N/A    760903      C   ...nda3/envs/comp/bin/python     2745MiB |\n",
      "|    5   N/A  N/A    758130      C   ...nda3/envs/comp/bin/python     3837MiB |\n",
      "|    5   N/A  N/A    758818      C   ...nda3/envs/comp/bin/python     1581MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facb418-0c6a-43ed-9288-af6d97184044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
