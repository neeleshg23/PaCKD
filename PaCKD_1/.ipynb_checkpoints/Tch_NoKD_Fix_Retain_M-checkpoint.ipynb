{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7beb99-5868-4f71-ad69-533b538aeb62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], 'src'))\n",
    "\n",
    "processed_dir = '/data/pengmiao/PaCKD_0/processed'\n",
    "\n",
    "train_loader = torch.load(os.path.join(processed_dir, f\"bc-3.train.pt\"))\n",
    "test_loader = torch.load(os.path.join(processed_dir, f\"bc-3.test.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ded044-6498-4b2b-961e-5e94ca45f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef3f555-7e64-4f62-bbbf-dc5c47af04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(ep, train_loader, model_save_path):\n",
    "    global steps\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#d,t: (torch.Size([64, 1, 784]),64)        \n",
    "        optimizer.zero_grad()\n",
    "        output = sigmoid(model(data))\n",
    "        loss = F.binary_cross_entropy(output, target, reduction='mean')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss/=len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = sigmoid(model(data))\n",
    "            test_loss += F.binary_cross_entropy(output, target, reduction='mean').item()\n",
    "            thresh=0.5\n",
    "            output_bin=(output>=thresh)*1\n",
    "            correct+=(output_bin&target.int()).sum()\n",
    "        test_loss /=  len(test_loader)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89b4d2f-1218-411a-925f-c73665d0bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def run_epoch(epochs, early_stop, loading, model_load_path, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_load_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7ac37-e94a-49b6-ba4d-93d6da11539c",
   "metadata": {},
   "source": [
    "Retraining K=2, Past IP, Teacher 2 ResNet -> Teacher No KD No Cluster by introducing entire trace's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52e2cb1b-eb55-4f0b-a268-23f30e75672e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Model Loaded------------\n",
      "Epoch: 1 - loss: 0.2215119156 - test_loss: 0.2008387401\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2170958445 - test_loss: 0.2085854665\n",
      "Early Stop Left: 14\n",
      "Epoch: 3 - loss: 0.2158046641 - test_loss: 0.2338229451\n",
      "Early Stop Left: 13\n",
      "Epoch: 4 - loss: 0.2171713014 - test_loss: 0.2151271666\n",
      "Early Stop Left: 12\n",
      "Epoch: 5 - loss: 0.2160396559 - test_loss: 0.2090957304\n",
      "Early Stop Left: 11\n",
      "Epoch: 6 - loss: 0.2161202540 - test_loss: 0.2329467156\n",
      "Early Stop Left: 10\n",
      "Epoch: 7 - loss: 0.2143578019 - test_loss: 0.2059087671\n",
      "Early Stop Left: 9\n",
      "Epoch: 8 - loss: 0.2141948035 - test_loss: 0.2270359972\n",
      "Early Stop Left: 8\n",
      "Epoch: 9 - loss: 0.2149632967 - test_loss: 0.2280208452\n",
      "Early Stop Left: 7\n",
      "Epoch: 10 - loss: 0.2146963712 - test_loss: 0.2191182222\n",
      "Early Stop Left: 6\n",
      "Epoch: 11 - loss: 0.2153943658 - test_loss: 0.2153695932\n",
      "Early Stop Left: 5\n",
      "Epoch: 12 - loss: 0.2170695223 - test_loss: 0.2265231647\n",
      "Early Stop Left: 4\n",
      "Epoch: 13 - loss: 0.2157253964 - test_loss: 0.2052513837\n",
      "Early Stop Left: 3\n",
      "Epoch: 15 - loss: 0.2167951740 - test_loss: 0.2211169753\n",
      "Early Stop Left: 1\n",
      "Epoch: 16 - loss: 0.2161507217 - test_loss: 0.2130230412\n",
      "Early Stop Left: 0\n",
      "-------- Early Stop! --------\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "\n",
    "device = torch.device(f\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = True\n",
    "model_load_path = '/data/pengmiao/PaCKD_2/model/i/bc-3.teacher_2.r.pth'\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.1.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.1.r.tsv'\n",
    "\n",
    "init_dataloader('1')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_load_path, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af80d8b8-89fb-4545-b277-147fa3af0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\",topk=2,threshold=0.5):\n",
    "    y_score=np.stack(test_df[\"y_score\"])\n",
    "    y_real=np.stack(test_df[\"future\"])\n",
    "    best_threshold=0\n",
    "    if throttle_type==\"roc\":\n",
    "        print(\"throttleing by roc curve\")\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        gmeans=dict()\n",
    "        ix=dict()\n",
    "        #pdb.set_trace()\n",
    "        for i in range(BITMAP_SIZE):\n",
    "            fpr[i], tpr[i], threshold[i] =roc_curve(y_real[:,i],y_score[:,i])\n",
    "            roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "            #best:\n",
    "            gmeans[i] = sqrt(tpr[i]*(1-fpr[i]))\n",
    "            ix[i]=nanargmax(gmeans[i])\n",
    "            best_threshold_list.append(threshold[i][ix[i]])\n",
    "            #print('Dimension: i=%d, Best threshold=%f, G-Mean=%.3f' %(i, threshold[i][ix[i]], gmeans[i][ix[i]]))\n",
    "        if optimal_type==\"indiv\":\n",
    "            best_threshold=best_threshold_list\n",
    "            y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "        elif optimal_type==\"micro\":\n",
    "            fpr[\"micro\"], tpr[\"micro\"], threshold[\"micro\"] = roc_curve(y_real.ravel(), y_score.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "            #best:\n",
    "            gmeans[\"micro\"] = sqrt(tpr[\"micro\"]*(1-fpr[\"micro\"]))\n",
    "            ix[\"micro\"]=nanargmax(gmeans[\"micro\"])\n",
    "            best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "            print('Best micro threshold=%f, G-Mean=%.3f' %(best_threshold, gmeans[\"micro\"][ix[\"micro\"]]))\n",
    "            \n",
    "            y_pred_bin = (y_score-best_threshold >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "            \n",
    "    if throttle_type==\"f1\":\n",
    "        print(\"throttleing by precision-recall curve\")\n",
    "        p = dict()\n",
    "        r = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        fscore=dict()\n",
    "        ix=dict()\n",
    "        \n",
    "        p[\"micro\"], r[\"micro\"], threshold[\"micro\"]=precision_recall_curve(y_real.ravel(),y_score.ravel())\n",
    "        fscore[\"micro\"] = (2 * p[\"micro\"] * r[\"micro\"]) / (p[\"micro\"] + r[\"micro\"])\n",
    "        ix[\"micro\"]=nanargmax(fscore[\"micro\"])\n",
    "        best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "        print('Best micro threshold=%f, fscore=%.3f' %(best_threshold, fscore[\"micro\"][ix[\"micro\"]]))\n",
    "        y_pred_bin = (y_score-best_threshold >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type==\"topk\":\n",
    "        print(\"throttleing by topk:\",topk)\n",
    "        pred_index = torch.tensor(y_score).topk(topk)[1].cpu().detach().numpy()\n",
    "        y_pred_bin=[to_bitmap(a,BITMAP_SIZE) for a in pred_index]\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type ==\"fixed_threshold\":\n",
    "        print(\"throttleing by fixed threshold:\",threshold)\n",
    "        best_threshold=threshold\n",
    "        y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "    \n",
    "    return test_df, best_threshold\n",
    "\n",
    "def model_prediction(test_loader, test_df, model_save_path):\n",
    "    print(\"predicting\")\n",
    "    prediction = []\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data, _ in tqdm(test_loader):\n",
    "        output = sigmoid(model(data))\n",
    "        prediction.extend(output.cpu().detach().numpy())\n",
    "    test_df[\"y_score\"] = prediction\n",
    "\n",
    "    return test_df[['id', 'cycle', 'addr', 'ip', 'block_address', 'future', 'y_score']]\n",
    "\n",
    "def evaluate(y_test,y_pred_bin):\n",
    "    f1_score_res=f1_score(y_test, y_pred_bin, average='micro')\n",
    "    #recall: tp / (tp + fn)\n",
    "    recall_score_res=recall_score(y_test, y_pred_bin, average='micro')\n",
    "    #precision: tp / (tp + fp)\n",
    "    precision_score_res=precision_score(y_test, y_pred_bin, average='micro',zero_division=0)\n",
    "    print(\"p,r,f1:\",precision_score_res,recall_score_res,f1_score_res)\n",
    "    return precision_score_res,recall_score_res,f1_score_res\n",
    "\n",
    "def run_val(test_loader, test_df, app_name, model_save_path):\n",
    "    res = {}\n",
    "\n",
    "    print(\"Validation start\")\n",
    "    test_df = model_prediction(test_loader, test_df, model_save_path)\n",
    "    df_res, threshold=threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\")\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"app\"], res[\"opt_th\"], res[\"p\"], res[\"r\"], res[\"f1\"]=[app_name],[threshold],[p],[r],[f1]\n",
    "\n",
    "    df_res, _ =threshold_throttleing(test_df,throttle_type=\"fixed_threshold\",threshold=0.5)\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"p_5\"],  res[\"r_5\"], res[\"f1_5\"]=[p],[r],[f1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714dfd7-4211-4330-b04b-020089a20b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = torch.load(os.path.join(processed_dir, 'bc-3.df.pt'))\n",
    "\n",
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810de9a-8792-496d-8579-4c832e812005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
