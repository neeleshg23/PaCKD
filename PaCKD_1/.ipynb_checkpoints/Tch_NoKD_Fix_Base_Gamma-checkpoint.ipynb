{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7beb99-5868-4f71-ad69-533b538aeb62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengmiao/anaconda3/envs/comp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], 'src'))\n",
    "\n",
    "processed_dir = '/data/pengmiao/PaCKD_0/processed'\n",
    "\n",
    "train_loader = torch.load(os.path.join(processed_dir, f\"bc-3.train.pt\"))\n",
    "test_loader = torch.load(os.path.join(processed_dir, f\"bc-3.test.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb2f0539-4036-42b3-a2fb-64907f1fe7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(ep, train_loader, model_save_path):\n",
    "    global steps\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#d,t: (torch.Size([64, 1, 784]),64)        \n",
    "        optimizer.zero_grad()\n",
    "        output = sigmoid(model(data))\n",
    "        loss = F.binary_cross_entropy(output, target, reduction='mean')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss/=len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = sigmoid(model(data))\n",
    "            test_loss += F.binary_cross_entropy(output, target, reduction='mean').item()\n",
    "            thresh=0.5\n",
    "            output_bin=(output>=thresh)*1\n",
    "            correct+=(output_bin&target.int()).sum()\n",
    "        test_loss /=  len(test_loader)\n",
    "        return test_loss\n",
    "\n",
    "import csv\n",
    "\n",
    "def run_epoch(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7ac37-e94a-49b6-ba4d-93d6da11539c",
   "metadata": {},
   "source": [
    "Baseline Teacher R Training No Cluster No KD, lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200fd17-2ad1-4b90-b8cb-471bd69a5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)\n",
    "\n",
    "device = torch.device(f\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = False\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.5.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.5.r.tsv'\n",
    "\n",
    "init_dataloader('2')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12331ea1-fd90-4258-aa0f-f828cdd9eb9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy import nanargmax, sqrt\n",
    "from sklearn.metrics import auc, f1_score, precision_score, recall_score, precision_recall_curve, roc_curve\n",
    "import numpy as np\n",
    "def threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\",topk=2,threshold=0.5):\n",
    "    y_score=np.stack(test_df[\"y_score\"])\n",
    "    y_real=np.stack(test_df[\"future\"])\n",
    "    best_threshold=0\n",
    "    if throttle_type==\"roc\":\n",
    "        print(\"throttleing by roc curve\")\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        gmeans=dict()\n",
    "        ix=dict()\n",
    "        #pdb.set_trace()\n",
    "        for i in range(BITMAP_SIZE):\n",
    "            fpr[i], tpr[i], threshold[i] =roc_curve(y_real[:,i],y_score[:,i])\n",
    "            roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "            #best:\n",
    "            gmeans[i] = sqrt(tpr[i]*(1-fpr[i]))\n",
    "            ix[i]=nanargmax(gmeans[i])\n",
    "            best_threshold_list.append(threshold[i][ix[i]])\n",
    "            #print('Dimension: i=%d, Best threshold=%f, G-Mean=%.3f' %(i, threshold[i][ix[i]], gmeans[i][ix[i]]))\n",
    "        if optimal_type==\"indiv\":\n",
    "            best_threshold=best_threshold_list\n",
    "            y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "        elif optimal_type==\"micro\":\n",
    "            fpr[\"micro\"], tpr[\"micro\"], threshold[\"micro\"] = roc_curve(y_real.ravel(), y_score.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "            #best:\n",
    "            gmeans[\"micro\"] = sqrt(tpr[\"micro\"]*(1-fpr[\"micro\"]))\n",
    "            ix[\"micro\"]=nanargmax(gmeans[\"micro\"])\n",
    "            best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "            print('Best micro threshold=%f, G-Mean=%.3f' %(best_threshold, gmeans[\"micro\"][ix[\"micro\"]]))\n",
    "            \n",
    "            y_pred_bin = (y_score-best_threshold >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "            \n",
    "    if throttle_type==\"f1\":\n",
    "        print(\"throttleing by precision-recall curve\")\n",
    "        p = dict()\n",
    "        r = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        fscore=dict()\n",
    "        ix=dict()\n",
    "        \n",
    "        p[\"micro\"], r[\"micro\"], threshold[\"micro\"]=precision_recall_curve(y_real.ravel(),y_score.ravel())\n",
    "        fscore[\"micro\"] = (2 * p[\"micro\"] * r[\"micro\"]) / (p[\"micro\"] + r[\"micro\"])\n",
    "        ix[\"micro\"]=nanargmax(fscore[\"micro\"])\n",
    "        best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "        print('Best micro threshold=%f, fscore=%.3f' %(best_threshold, fscore[\"micro\"][ix[\"micro\"]]))\n",
    "        y_pred_bin = (y_score-best_threshold >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type==\"topk\":\n",
    "        print(\"throttleing by topk:\",topk)\n",
    "        pred_index = torch.tensor(y_score).topk(topk)[1].cpu().detach().numpy()\n",
    "        y_pred_bin=[to_bitmap(a,BITMAP_SIZE) for a in pred_index]\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type ==\"fixed_threshold\":\n",
    "        print(\"throttleing by fixed threshold:\",threshold)\n",
    "        best_threshold=threshold\n",
    "        y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "    \n",
    "    return test_df, best_threshold\n",
    "\n",
    "def model_prediction(test_loader, test_df, model_save_path):\n",
    "    print(\"predicting\")\n",
    "    prediction = []\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data, _ in tqdm(test_loader):\n",
    "        output = sigmoid(model(data))\n",
    "        prediction.extend(output.cpu().detach().numpy())\n",
    "    test_df[\"y_score\"] = prediction\n",
    "\n",
    "    return test_df[['id', 'cycle', 'addr', 'ip', 'block_address', 'future', 'y_score']]\n",
    "\n",
    "def evaluate(y_test,y_pred_bin):\n",
    "    f1_score_res=f1_score(y_test, y_pred_bin, average='micro')\n",
    "    #recall: tp / (tp + fn)\n",
    "    recall_score_res=recall_score(y_test, y_pred_bin, average='micro')\n",
    "    #precision: tp / (tp + fp)\n",
    "    precision_score_res=precision_score(y_test, y_pred_bin, average='micro',zero_division=0)\n",
    "    print(\"p,r,f1:\",precision_score_res,recall_score_res,f1_score_res)\n",
    "    return precision_score_res,recall_score_res,f1_score_res\n",
    "\n",
    "def run_val(test_loader, test_df, app_name, model_save_path):\n",
    "    res = {}\n",
    "\n",
    "    print(\"Validation start\")\n",
    "    test_df = model_prediction(test_loader, test_df, model_save_path)\n",
    "    df_res, threshold=threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\")\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"app\"], res[\"opt_th\"], res[\"p\"], res[\"r\"], res[\"f1\"]=[app_name],[threshold],[p],[r],[f1]\n",
    "\n",
    "    df_res, _ =threshold_throttleing(test_df,throttle_type=\"fixed_threshold\",threshold=0.5)\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"p_5\"],  res[\"r_5\"], res[\"f1_5\"]=[p],[r],[f1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abda7b0c-39f8-45d9-b26a-cfcfe15ae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = torch.load(os.path.join(processed_dir, 'bc-3.df.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "346240b1-74dd-4bea-b39d-5e40d16d0b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232/1232 [00:23<00:00, 53.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throttleing by precision-recall curve\n",
      "Best micro threshold=0.005709, fscore=0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_758818/2052061821.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.12518123402169803 0.9998383157608094 0.22250456752206813\n",
      "throttleing by fixed threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_758818/2052061821.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.1443085633810913 0.009936555262861566 0.018592873830261616\n"
     ]
    }
   ],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91ed3d-527e-432e-9a7d-86c5193077d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 0.2241746771 - test_loss: 0.2272103940\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2166795606 - test_loss: 0.2249972676\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 3 - loss: 0.2158045309 - test_loss: 0.2233762210\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 4 - loss: 0.2150387856 - test_loss: 0.2129068795\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 5 - loss: 0.2153383172 - test_loss: 0.2155507126\n",
      "Early Stop Left: 14\n",
      "Epoch: 6 - loss: 0.2147040660 - test_loss: 0.2211136417\n",
      "Early Stop Left: 13\n",
      "Epoch: 7 - loss: 0.2149072385 - test_loss: 0.2188266594\n",
      "Early Stop Left: 12\n",
      "Epoch: 8 - loss: 0.2151481895 - test_loss: 0.2148469575\n",
      "Early Stop Left: 11\n",
      "Epoch: 9 - loss: 0.2152875670 - test_loss: 0.2186925722\n",
      "Early Stop Left: 10\n",
      "Epoch: 10 - loss: 0.2162218366 - test_loss: 0.2190096300\n",
      "Early Stop Left: 9\n",
      "Epoch: 11 - loss: 0.2158238083 - test_loss: 0.2141067390\n",
      "Early Stop Left: 8\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = False\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.05.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.05.r.tsv'\n",
    "\n",
    "init_dataloader('2')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca678d7-00d7-4305-adc3-646fa6582a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf00b98-17eb-4d5a-b9ae-9cc8b1544745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
