{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7beb99-5868-4f71-ad69-533b538aeb62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], 'src'))\n",
    "\n",
    "processed_dir = '/data/pengmiao/PaCKD_0/processed'\n",
    "\n",
    "train_loader = torch.load(os.path.join(processed_dir, f\"bc-3.train.pt\"))\n",
    "test_loader = torch.load(os.path.join(processed_dir, f\"bc-3.test.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ded044-6498-4b2b-961e-5e94ca45f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef3f555-7e64-4f62-bbbf-dc5c47af04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(ep, train_loader, model_save_path):\n",
    "    global steps\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#d,t: (torch.Size([64, 1, 784]),64)        \n",
    "        optimizer.zero_grad()\n",
    "        output = sigmoid(model(data))\n",
    "        loss = F.binary_cross_entropy(output, target, reduction='mean')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss/=len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = sigmoid(model(data))\n",
    "            test_loss += F.binary_cross_entropy(output, target, reduction='mean').item()\n",
    "            thresh=0.5\n",
    "            output_bin=(output>=thresh)*1\n",
    "            correct+=(output_bin&target.int()).sum()\n",
    "        test_loss /=  len(test_loader)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89b4d2f-1218-411a-925f-c73665d0bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def run_epoch(epochs, early_stop, loading, model_load_path, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_load_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7ac37-e94a-49b6-ba4d-93d6da11539c",
   "metadata": {},
   "source": [
    "Retraining K=2, Past IP, Teacher 2 ResNet -> Teacher No KD No Cluster by introducing entire trace's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52e2cb1b-eb55-4f0b-a268-23f30e75672e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Model Loaded------------\n",
      "Epoch: 1 - loss: 0.2215119156 - test_loss: 0.2008387401\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2170958445 - test_loss: 0.2085854665\n",
      "Early Stop Left: 14\n",
      "Epoch: 3 - loss: 0.2158046641 - test_loss: 0.2338229451\n",
      "Early Stop Left: 13\n",
      "Epoch: 4 - loss: 0.2171713014 - test_loss: 0.2151271666\n",
      "Early Stop Left: 12\n",
      "Epoch: 5 - loss: 0.2160396559 - test_loss: 0.2090957304\n",
      "Early Stop Left: 11\n",
      "Epoch: 6 - loss: 0.2161202540 - test_loss: 0.2329467156\n",
      "Early Stop Left: 10\n",
      "Epoch: 7 - loss: 0.2143578019 - test_loss: 0.2059087671\n",
      "Early Stop Left: 9\n",
      "Epoch: 8 - loss: 0.2141948035 - test_loss: 0.2270359972\n",
      "Early Stop Left: 8\n",
      "Epoch: 9 - loss: 0.2149632967 - test_loss: 0.2280208452\n",
      "Early Stop Left: 7\n",
      "Epoch: 10 - loss: 0.2146963712 - test_loss: 0.2191182222\n",
      "Early Stop Left: 6\n",
      "Epoch: 11 - loss: 0.2153943658 - test_loss: 0.2153695932\n",
      "Early Stop Left: 5\n",
      "Epoch: 12 - loss: 0.2170695223 - test_loss: 0.2265231647\n",
      "Early Stop Left: 4\n",
      "Epoch: 13 - loss: 0.2157253964 - test_loss: 0.2052513837\n",
      "Early Stop Left: 3\n",
      "Epoch: 15 - loss: 0.2167951740 - test_loss: 0.2211169753\n",
      "Early Stop Left: 1\n",
      "Epoch: 16 - loss: 0.2161507217 - test_loss: 0.2130230412\n",
      "Early Stop Left: 0\n",
      "-------- Early Stop! --------\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "\n",
    "device = torch.device(f\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = True\n",
    "model_load_path = '/data/pengmiao/PaCKD_2/model/i/bc-3.teacher_2.r.pth'\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.1.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.1.r.tsv'\n",
    "\n",
    "init_dataloader('1')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_load_path, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af80d8b8-89fb-4545-b277-147fa3af0156",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy import nanargmax, sqrt\n",
    "from sklearn.metrics import auc, f1_score, precision_score, recall_score, precision_recall_curve, roc_curve\n",
    "import numpy as np\n",
    "def threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\",topk=2,threshold=0.5):\n",
    "    y_score=np.stack(test_df[\"y_score\"])\n",
    "    y_real=np.stack(test_df[\"future\"])\n",
    "    best_threshold=0\n",
    "    if throttle_type==\"roc\":\n",
    "        print(\"throttleing by roc curve\")\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        gmeans=dict()\n",
    "        ix=dict()\n",
    "        #pdb.set_trace()\n",
    "        for i in range(BITMAP_SIZE):\n",
    "            fpr[i], tpr[i], threshold[i] =roc_curve(y_real[:,i],y_score[:,i])\n",
    "            roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "            #best:\n",
    "            gmeans[i] = sqrt(tpr[i]*(1-fpr[i]))\n",
    "            ix[i]=nanargmax(gmeans[i])\n",
    "            best_threshold_list.append(threshold[i][ix[i]])\n",
    "            #print('Dimension: i=%d, Best threshold=%f, G-Mean=%.3f' %(i, threshold[i][ix[i]], gmeans[i][ix[i]]))\n",
    "        if optimal_type==\"indiv\":\n",
    "            best_threshold=best_threshold_list\n",
    "            y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "        elif optimal_type==\"micro\":\n",
    "            fpr[\"micro\"], tpr[\"micro\"], threshold[\"micro\"] = roc_curve(y_real.ravel(), y_score.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "            #best:\n",
    "            gmeans[\"micro\"] = sqrt(tpr[\"micro\"]*(1-fpr[\"micro\"]))\n",
    "            ix[\"micro\"]=nanargmax(gmeans[\"micro\"])\n",
    "            best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "            print('Best micro threshold=%f, G-Mean=%.3f' %(best_threshold, gmeans[\"micro\"][ix[\"micro\"]]))\n",
    "            \n",
    "            y_pred_bin = (y_score-best_threshold >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "            \n",
    "    if throttle_type==\"f1\":\n",
    "        print(\"throttleing by precision-recall curve\")\n",
    "        p = dict()\n",
    "        r = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        fscore=dict()\n",
    "        ix=dict()\n",
    "        \n",
    "        p[\"micro\"], r[\"micro\"], threshold[\"micro\"]=precision_recall_curve(y_real.ravel(),y_score.ravel())\n",
    "        fscore[\"micro\"] = (2 * p[\"micro\"] * r[\"micro\"]) / (p[\"micro\"] + r[\"micro\"])\n",
    "        ix[\"micro\"]=nanargmax(fscore[\"micro\"])\n",
    "        best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "        print('Best micro threshold=%f, fscore=%.3f' %(best_threshold, fscore[\"micro\"][ix[\"micro\"]]))\n",
    "        y_pred_bin = (y_score-best_threshold >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type==\"topk\":\n",
    "        print(\"throttleing by topk:\",topk)\n",
    "        pred_index = torch.tensor(y_score).topk(topk)[1].cpu().detach().numpy()\n",
    "        y_pred_bin=[to_bitmap(a,BITMAP_SIZE) for a in pred_index]\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type ==\"fixed_threshold\":\n",
    "        print(\"throttleing by fixed threshold:\",threshold)\n",
    "        best_threshold=threshold\n",
    "        y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "    \n",
    "    return test_df, best_threshold\n",
    "\n",
    "def model_prediction(test_loader, test_df, model_save_path):\n",
    "    print(\"predicting\")\n",
    "    prediction = []\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data, _ in tqdm(test_loader):\n",
    "        output = sigmoid(model(data))\n",
    "        prediction.extend(output.cpu().detach().numpy())\n",
    "    test_df[\"y_score\"] = prediction\n",
    "\n",
    "    return test_df[['id', 'cycle', 'addr', 'ip', 'block_address', 'future', 'y_score']]\n",
    "\n",
    "def evaluate(y_test,y_pred_bin):\n",
    "    f1_score_res=f1_score(y_test, y_pred_bin, average='micro')\n",
    "    #recall: tp / (tp + fn)\n",
    "    recall_score_res=recall_score(y_test, y_pred_bin, average='micro')\n",
    "    #precision: tp / (tp + fp)\n",
    "    precision_score_res=precision_score(y_test, y_pred_bin, average='micro',zero_division=0)\n",
    "    print(\"p,r,f1:\",precision_score_res,recall_score_res,f1_score_res)\n",
    "    return precision_score_res,recall_score_res,f1_score_res\n",
    "\n",
    "def run_val(test_loader, test_df, app_name, model_save_path):\n",
    "    res = {}\n",
    "\n",
    "    print(\"Validation start\")\n",
    "    test_df = model_prediction(test_loader, test_df, model_save_path)\n",
    "    df_res, threshold=threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\")\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"app\"], res[\"opt_th\"], res[\"p\"], res[\"r\"], res[\"f1\"]=[app_name],[threshold],[p],[r],[f1]\n",
    "\n",
    "    df_res, _ =threshold_throttleing(test_df,throttle_type=\"fixed_threshold\",threshold=0.5)\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"p_5\"],  res[\"r_5\"], res[\"f1_5\"]=[p],[r],[f1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c714dfd7-4211-4330-b04b-020089a20b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_758130/49051896.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bc-3.df.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bc-3.txt.xz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_758130/1261147153.py\u001b[0m in \u001b[0;36mrun_val\u001b[0;34m(test_loader, test_df, app_name, model_save_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mdf_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold_throttleing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthrottle_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimal_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"future\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_758130/1261147153.py\u001b[0m in \u001b[0;36mmodel_prediction\u001b[0;34m(test_loader, test_df, model_save_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "test_df = torch.load(os.path.join(processed_dir, 'bc-3.df.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1810de9a-8792-496d-8579-4c832e812005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232/1232 [00:25<00:00, 47.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throttleing by precision-recall curve\n",
      "Best micro threshold=0.056499, fscore=0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_758130/2052061821.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.12727627006169742 0.9965133991113106 0.22572285897364894\n",
      "throttleing by fixed threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_758130/2052061821.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.6162575543782114 0.01832335620858573 0.03558854827404823\n"
     ]
    }
   ],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e345500-0a81-4f69-bcae-475f75576821",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_epoch_no_load(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd7c865e-6d5c-4352-93df-b377ed8ab1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 0.2244955619 - test_loss: 0.2222966755\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2179210031 - test_loss: 0.2229660526\n",
      "Early Stop Left: 14\n",
      "Epoch: 3 - loss: 0.2158057630 - test_loss: 0.2224106195\n",
      "Early Stop Left: 13\n",
      "Epoch: 4 - loss: 0.2149826372 - test_loss: 0.2238253510\n",
      "Early Stop Left: 12\n",
      "Epoch: 5 - loss: 0.2155781214 - test_loss: 0.2249734929\n",
      "Early Stop Left: 11\n",
      "Epoch: 6 - loss: 0.2152852979 - test_loss: 0.2204575997\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 7 - loss: 0.2180929596 - test_loss: 0.2136492020\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 8 - loss: 0.2153300945 - test_loss: 0.2247993299\n",
      "Early Stop Left: 14\n",
      "Epoch: 9 - loss: 0.2165446176 - test_loss: 0.2289228892\n",
      "Early Stop Left: 13\n",
      "Epoch: 10 - loss: 0.2159636657 - test_loss: 0.2038170932\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 11 - loss: 0.2165088190 - test_loss: 0.2206761034\n",
      "Early Stop Left: 14\n",
      "Epoch: 12 - loss: 0.2159929908 - test_loss: 0.2188543278\n",
      "Early Stop Left: 13\n",
      "Epoch: 13 - loss: 0.2162346642 - test_loss: 0.2110358246\n",
      "Early Stop Left: 12\n",
      "Epoch: 14 - loss: 0.2158815866 - test_loss: 0.2126113702\n",
      "Early Stop Left: 11\n",
      "Epoch: 15 - loss: 0.2168791612 - test_loss: 0.2065305811\n",
      "Early Stop Left: 10\n",
      "Epoch: 16 - loss: 0.2158168006 - test_loss: 0.1980198086\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 17 - loss: 0.2160675473 - test_loss: 0.2114021118\n",
      "Early Stop Left: 14\n",
      "Epoch: 18 - loss: 0.2172935969 - test_loss: 0.1945648851\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 19 - loss: 0.2157218224 - test_loss: 0.2043995595\n",
      "Early Stop Left: 14\n",
      "Epoch: 20 - loss: 0.2156756872 - test_loss: 0.2136585954\n",
      "Early Stop Left: 13\n",
      "Epoch: 21 - loss: 0.2160649904 - test_loss: 0.2210337632\n",
      "Early Stop Left: 12\n",
      "Epoch: 22 - loss: 0.2172544978 - test_loss: 0.2168668431\n",
      "Early Stop Left: 11\n",
      "Epoch: 23 - loss: 0.2171966032 - test_loss: 0.2134742361\n",
      "Early Stop Left: 10\n",
      "Epoch: 24 - loss: 0.2162971705 - test_loss: 0.2160564803\n",
      "Early Stop Left: 9\n",
      "Epoch: 25 - loss: 0.2151299431 - test_loss: 0.2160130929\n",
      "Early Stop Left: 8\n",
      "Epoch: 26 - loss: 0.2145304396 - test_loss: 0.2174516338\n",
      "Early Stop Left: 7\n",
      "Epoch: 27 - loss: 0.2149946508 - test_loss: 0.2160543422\n",
      "Early Stop Left: 6\n",
      "Epoch: 28 - loss: 0.2143772218 - test_loss: 0.2173327715\n",
      "Early Stop Left: 5\n",
      "Epoch: 29 - loss: 0.2152143443 - test_loss: 0.2165404379\n",
      "Early Stop Left: 4\n",
      "Epoch: 30 - loss: 0.2133796241 - test_loss: 0.2166542631\n",
      "Early Stop Left: 3\n",
      "Epoch: 31 - loss: 0.2127726784 - test_loss: 0.2176360344\n",
      "Early Stop Left: 2\n",
      "Epoch: 32 - loss: 0.2121528169 - test_loss: 0.2176349038\n",
      "Early Stop Left: 1\n",
      "Epoch: 33 - loss: 0.2127007280 - test_loss: 0.2187384234\n",
      "Early Stop Left: 0\n",
      "-------- Early Stop! --------\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('r')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = False\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.05.r.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.05.r.tsv'\n",
    "\n",
    "init_dataloader('3')\n",
    "\n",
    "run_epoch_no_load(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8562bbb-28f9-4349-8dad-5141da2fa7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232/1232 [00:22<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throttleing by precision-recall curve\n",
      "Best micro threshold=0.157348, fscore=0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_758130/2052061821.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.15597639930489698 0.7527054404074839 0.25840570197623247\n",
      "throttleing by fixed threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_758130/2052061821.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p,r,f1: 0.8383117360588698 0.029330945868631258 0.05667880721763658\n"
     ]
    }
   ],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca63483-583e-4b62-a01d-441ec7689786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
