{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7beb99-5868-4f71-ad69-533b538aeb62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "processed_dir = '/data/pengmiao/PaCKD_0/processed'\n",
    "\n",
    "train_loader = torch.load(os.path.join(processed_dir, f\"bc-3.train.pt\"))\n",
    "test_loader = torch.load(os.path.join(processed_dir, f\"bc-3.test.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df5cb928-aac4-4f63-93f8-ffff2844b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import select_tch\n",
    "\n",
    "model = select_tch('m')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36cb7d67-bd0b-45b0-bd7c-194caf2ee52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(ep, train_loader, model_save_path):\n",
    "    global steps\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#d,t: (torch.Size([64, 1, 784]),64)        \n",
    "        optimizer.zero_grad()\n",
    "        output = sigmoid(model(data))\n",
    "        loss = F.binary_cross_entropy(output, target, reduction='mean')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss/=len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = sigmoid(model(data))\n",
    "            test_loss += F.binary_cross_entropy(output, target, reduction='mean').item()\n",
    "            thresh=0.5\n",
    "            output_bin=(output>=thresh)*1\n",
    "            correct+=(output_bin&target.int()).sum()\n",
    "        test_loss /=  len(test_loader)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1627ab25-288a-48c2-85ab-495294515034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def run_epoch(epochs, early_stop, loading, model_load_path, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_load_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dac13d-1387-4104-a3b6-94c26ecee904",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Model Loaded------------\n",
      "Epoch: 1 - loss: 0.2342319620 - test_loss: 0.2266077912\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2313984578 - test_loss: 0.2288997499\n",
      "Early Stop Left: 14\n",
      "Epoch: 3 - loss: 0.2303736973 - test_loss: 0.2261069042\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 4 - loss: 0.2284807163 - test_loss: 0.2225959873\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 5 - loss: 0.2279223187 - test_loss: 0.2268306982\n",
      "Early Stop Left: 14\n",
      "Epoch: 6 - loss: 0.2267487994 - test_loss: 0.2227692970\n",
      "Early Stop Left: 13\n",
      "Epoch: 7 - loss: 0.2264660713 - test_loss: 0.2295580302\n",
      "Early Stop Left: 12\n",
      "Epoch: 8 - loss: 0.2265785517 - test_loss: 0.2226403109\n",
      "Early Stop Left: 11\n",
      "Epoch: 9 - loss: 0.2256653242 - test_loss: 0.2270950673\n",
      "Early Stop Left: 10\n",
      "Epoch: 10 - loss: 0.2261850593 - test_loss: 0.2312971368\n",
      "Early Stop Left: 9\n",
      "Epoch: 11 - loss: 0.2255497147 - test_loss: 0.2297412506\n",
      "Early Stop Left: 8\n",
      "Epoch: 12 - loss: 0.2270941808 - test_loss: 0.2238346085\n",
      "Early Stop Left: 7\n",
      "Epoch: 13 - loss: 0.2262545324 - test_loss: 0.2216395242\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 14 - loss: 0.2266549981 - test_loss: 0.2262415414\n",
      "Early Stop Left: 14\n",
      "Epoch: 15 - loss: 0.2266975043 - test_loss: 0.2261050395\n",
      "Early Stop Left: 13\n",
      "Epoch: 16 - loss: 0.2245828618 - test_loss: 0.2265272362\n",
      "Early Stop Left: 12\n",
      "Epoch: 17 - loss: 0.2235990214 - test_loss: 0.2118401913\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 19 - loss: 0.2247831417 - test_loss: 0.2296040799\n",
      "Early Stop Left: 13\n",
      "Epoch: 20 - loss: 0.2252444463 - test_loss: 0.2329438642\n",
      "Early Stop Left: 12\n",
      "Epoch: 21 - loss: 0.2245606306 - test_loss: 0.2311339611\n",
      "Early Stop Left: 11\n",
      "Epoch: 22 - loss: 0.2236872182 - test_loss: 0.2297260497\n",
      "Early Stop Left: 10\n",
      "Epoch: 23 - loss: 0.2226401862 - test_loss: 0.2381380283\n",
      "Early Stop Left: 9\n",
      "Epoch: 24 - loss: 0.2227596351 - test_loss: 0.2233383671\n",
      "Early Stop Left: 8\n",
      "Epoch: 25 - loss: 0.2226517403 - test_loss: 0.2181650497\n",
      "Early Stop Left: 7\n",
      "Epoch: 26 - loss: 0.2226360742 - test_loss: 0.2180297019\n",
      "Early Stop Left: 6\n",
      "Epoch: 27 - loss: 0.2233292686 - test_loss: 0.2334580291\n",
      "Early Stop Left: 5\n",
      "Epoch: 28 - loss: 0.2226182986 - test_loss: 0.2334957649\n",
      "Early Stop Left: 4\n",
      "Epoch: 29 - loss: 0.2235812385 - test_loss: 0.2362800851\n",
      "Early Stop Left: 3\n",
      "Epoch: 30 - loss: 0.2237337716 - test_loss: 0.2325267152\n",
      "Early Stop Left: 2\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = True\n",
    "model_load_path = '/data/pengmiao/PaCKD_2/model/i/bc-3.teacher_2.m.pth'\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.1.m.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/bc-3.teacher.lr.1.m.tsv'\n",
    "\n",
    "init_dataloader('0')\n",
    "\n",
    "run_epoch(epochs, early_stop, loading, model_load_path, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d70524c4-d4fb-4d2e-a4ea-4729a3e7144c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy import nanargmax, sqrt\n",
    "from sklearn.metrics import auc, f1_score, precision_score, recall_score, precision_recall_curve, roc_curve\n",
    "import numpy as np\n",
    "def threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\",topk=2,threshold=0.5):\n",
    "    y_score=np.stack(test_df[\"y_score\"])\n",
    "    y_real=np.stack(test_df[\"future\"])\n",
    "    best_threshold=0\n",
    "    if throttle_type==\"roc\":\n",
    "        print(\"throttleing by roc curve\")\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        gmeans=dict()\n",
    "        ix=dict()\n",
    "        #pdb.set_trace()\n",
    "        for i in range(BITMAP_SIZE):\n",
    "            fpr[i], tpr[i], threshold[i] =roc_curve(y_real[:,i],y_score[:,i])\n",
    "            roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "            #best:\n",
    "            gmeans[i] = sqrt(tpr[i]*(1-fpr[i]))\n",
    "            ix[i]=nanargmax(gmeans[i])\n",
    "            best_threshold_list.append(threshold[i][ix[i]])\n",
    "            #print('Dimension: i=%d, Best threshold=%f, G-Mean=%.3f' %(i, threshold[i][ix[i]], gmeans[i][ix[i]]))\n",
    "        if optimal_type==\"indiv\":\n",
    "            best_threshold=best_threshold_list\n",
    "            y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "        elif optimal_type==\"micro\":\n",
    "            fpr[\"micro\"], tpr[\"micro\"], threshold[\"micro\"] = roc_curve(y_real.ravel(), y_score.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "            #best:\n",
    "            gmeans[\"micro\"] = sqrt(tpr[\"micro\"]*(1-fpr[\"micro\"]))\n",
    "            ix[\"micro\"]=nanargmax(gmeans[\"micro\"])\n",
    "            best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "            print('Best micro threshold=%f, G-Mean=%.3f' %(best_threshold, gmeans[\"micro\"][ix[\"micro\"]]))\n",
    "            \n",
    "            y_pred_bin = (y_score-best_threshold >0)*1\n",
    "            test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "            \n",
    "    if throttle_type==\"f1\":\n",
    "        print(\"throttleing by precision-recall curve\")\n",
    "        p = dict()\n",
    "        r = dict()\n",
    "        threshold=dict()\n",
    "        best_threshold_list=[]\n",
    "        fscore=dict()\n",
    "        ix=dict()\n",
    "        \n",
    "        p[\"micro\"], r[\"micro\"], threshold[\"micro\"]=precision_recall_curve(y_real.ravel(),y_score.ravel())\n",
    "        fscore[\"micro\"] = (2 * p[\"micro\"] * r[\"micro\"]) / (p[\"micro\"] + r[\"micro\"])\n",
    "        ix[\"micro\"]=nanargmax(fscore[\"micro\"])\n",
    "        best_threshold=threshold[\"micro\"][ix[\"micro\"]]\n",
    "        print('Best micro threshold=%f, fscore=%.3f' %(best_threshold, fscore[\"micro\"][ix[\"micro\"]]))\n",
    "        y_pred_bin = (y_score-best_threshold >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type==\"topk\":\n",
    "        print(\"throttleing by topk:\",topk)\n",
    "        pred_index = torch.tensor(y_score).topk(topk)[1].cpu().detach().numpy()\n",
    "        y_pred_bin=[to_bitmap(a,BITMAP_SIZE) for a in pred_index]\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)\n",
    "        \n",
    "    elif throttle_type ==\"fixed_threshold\":\n",
    "        print(\"throttleing by fixed threshold:\",threshold)\n",
    "        best_threshold=threshold\n",
    "        y_pred_bin = (y_score-np.array(best_threshold) >0)*1\n",
    "        test_df[\"predicted\"]= list(y_pred_bin)#(all,[length])\n",
    "    \n",
    "    return test_df, best_threshold\n",
    "\n",
    "def model_prediction(test_loader, test_df, model_save_path):\n",
    "    print(\"predicting\")\n",
    "    prediction = []\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data, _ in tqdm(test_loader):\n",
    "        output = sigmoid(model(data))\n",
    "        prediction.extend(output.cpu().detach().numpy())\n",
    "    test_df[\"y_score\"] = prediction\n",
    "\n",
    "    return test_df[['id', 'cycle', 'addr', 'ip', 'block_address', 'future', 'y_score']]\n",
    "\n",
    "def evaluate(y_test,y_pred_bin):\n",
    "    f1_score_res=f1_score(y_test, y_pred_bin, average='micro')\n",
    "    #recall: tp / (tp + fn)\n",
    "    recall_score_res=recall_score(y_test, y_pred_bin, average='micro')\n",
    "    #precision: tp / (tp + fp)\n",
    "    precision_score_res=precision_score(y_test, y_pred_bin, average='micro',zero_division=0)\n",
    "    print(\"p,r,f1:\",precision_score_res,recall_score_res,f1_score_res)\n",
    "    return precision_score_res,recall_score_res,f1_score_res\n",
    "\n",
    "def run_val(test_loader, test_df, app_name, model_save_path):\n",
    "    res = {}\n",
    "\n",
    "    print(\"Validation start\")\n",
    "    test_df = model_prediction(test_loader, test_df, model_save_path)\n",
    "    df_res, threshold=threshold_throttleing(test_df,throttle_type=\"f1\",optimal_type=\"micro\")\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"app\"], res[\"opt_th\"], res[\"p\"], res[\"r\"], res[\"f1\"]=[app_name],[threshold],[p],[r],[f1]\n",
    "\n",
    "    df_res, _ =threshold_throttleing(test_df,throttle_type=\"fixed_threshold\",threshold=0.5)\n",
    "    p,r,f1 = evaluate(np.stack(df_res[\"future\"]), np.stack(df_res[\"predicted\"]))\n",
    "    res[\"p_5\"],  res[\"r_5\"], res[\"f1_5\"]=[p],[r],[f1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cee6de6-953d-4e36-baf2-439085bc7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = torch.load(os.path.join(processed_dir, 'bc-3.df.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9e398b0-4254-42e5-86ca-afcab29d6c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1232/1232 [00:14<00:00, 84.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throttleing by precision-recall curve\n",
      "Best micro threshold=0.156979, fscore=0.223\n",
      "p,r,f1: 0.12577582265760828 0.9920547137882222 0.22324760986544828\n",
      "throttleing by fixed threshold: 0.5\n",
      "p,r,f1: 0.7800287691157917 0.019209354175361893 0.03749533075628421\n"
     ]
    }
   ],
   "source": [
    "res = run_val(test_loader, test_df, 'bc-3.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0c8a6df-0bab-4cb0-836a-5687a0d32d32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_epoch_no_load(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model):\n",
    "    if loading==True:\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        print(\"-------------Model Loaded------------\")\n",
    "        \n",
    "    best_loss=0\n",
    "    early_stop = early_stop\n",
    "    curr_early_stop = early_stop\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss=train(epoch,train_loader,model_save_path)\n",
    "        test_loss=test(test_loader)\n",
    "        print((f\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss=test_loss\n",
    "        if test_loss<=best_loss:\n",
    "            torch.save(model.state_dict(), model_save_path)    \n",
    "            best_loss=test_loss\n",
    "            print(\"-------- Save Best Model! --------\")\n",
    "            curr_early_stop = early_stop\n",
    "        else:\n",
    "            curr_early_stop -= 1\n",
    "            print(\"Early Stop Left: {}\".format(curr_early_stop))\n",
    "        if curr_early_stop == 0:\n",
    "            print(\"-------- Early Stop! --------\")\n",
    "            break\n",
    "\n",
    "        metrics_data.append([epoch+1, train_loss, test_loss])\n",
    "\n",
    "    with open(tsv_path, 'w') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['Epoch', 'Train Loss', 'Test Loss'])\n",
    "        writer.writerows(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bb6babd-1b96-4d6d-bdee-24a7e4ee0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - loss: 0.2723222866 - test_loss: 0.2238957433\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 2 - loss: 0.2423149876 - test_loss: 0.2232185440\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 3 - loss: 0.2418184550 - test_loss: 0.2230541049\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 4 - loss: 0.2417471518 - test_loss: 0.2229801263\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 5 - loss: 0.2419185829 - test_loss: 0.2227841806\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 6 - loss: 0.2421247070 - test_loss: 0.2225050773\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 7 - loss: 0.2423758314 - test_loss: 0.2221418514\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 8 - loss: 0.2426445829 - test_loss: 0.2217016178\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 9 - loss: 0.2429020118 - test_loss: 0.2214356048\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 10 - loss: 0.2431864370 - test_loss: 0.2211759286\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 11 - loss: 0.2434068637 - test_loss: 0.2209860322\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 12 - loss: 0.2435747316 - test_loss: 0.2208178012\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 13 - loss: 0.2437571238 - test_loss: 0.2206500028\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 14 - loss: 0.2438387013 - test_loss: 0.2206421528\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 15 - loss: 0.2440549754 - test_loss: 0.2203673020\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 16 - loss: 0.2442433027 - test_loss: 0.2201466662\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 17 - loss: 0.2442769724 - test_loss: 0.2201220208\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 18 - loss: 0.2443639541 - test_loss: 0.2199660835\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 19 - loss: 0.2445595182 - test_loss: 0.2197090255\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 20 - loss: 0.2447667485 - test_loss: 0.2195233509\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 21 - loss: 0.2448216064 - test_loss: 0.2194859254\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 22 - loss: 0.2449605040 - test_loss: 0.2192653613\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 23 - loss: 0.2452033491 - test_loss: 0.2190851045\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 24 - loss: 0.2451694640 - test_loss: 0.2190164404\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 25 - loss: 0.2453325450 - test_loss: 0.2187983102\n",
      "-------- Save Best Model! --------\n",
      "Epoch: 26 - loss: 0.2454927292 - test_loss: 0.2187178847\n",
      "-------- Save Best Model! --------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_757905/1134470606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0minit_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrun_epoch_no_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_757905/2577733826.py\u001b[0m in \u001b[0;36mrun_epoch_no_load\u001b[0;34m(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch+1} - loss: {train_loss:.10f} - test_loss: {test_loss:.10f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_757905/2213855526.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(ep, train_loader, model_save_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comp/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comp/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_loader import init_dataloader\n",
    "from utils import select_tch\n",
    "\n",
    "device = torch.device(f\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = select_tch('l')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "epochs = 50\n",
    "early_stop = 15\n",
    "loading = False\n",
    "model_save_path = '/data/pengmiao/PaCKD_1/model/cc-13.teacher.lr.05.l.pth'\n",
    "tsv_path = '/data/pengmiao/PaCKD_1/model/cc-13.teacher.lr.05.l.tsv'\n",
    "\n",
    "init_dataloader('4')\n",
    "\n",
    "run_epoch_no_load(epochs, early_stop, loading, model_save_path, train_loader, test_loader, tsv_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6244cdb-c07b-4172-bba3-2a36245a12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_val(test_loader, test_df, 'cc-13.txt.xz', model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb61fc-b721-401d-8631-d47d075168ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
